from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when
import pandas as pd

# üîß –°–ø–∏—Å–æ–∫ –æ–∂–∏–¥–∞–µ–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –º–æ–¥–µ–ª–∏
expected_columns = [
    'Number_of_Riders',
    'Number_of_Drivers',
    'Number_of_Past_Rides',
    'Average_Ratings',
    'Vehicle_Type',
    'Expected_Ride_Duration',
    'Time_of_Booking_Afternoon',
    'Time_of_Booking_Evening',
    'Time_of_Booking_Morning',
    'Time_of_Booking_Night',
    'Customer_Loyalty_Status_Gold',
    'Customer_Loyalty_Status_Regular',
    'Customer_Loyalty_Status_Silver',
    'Location_Category_Rural',
    'Location_Category_Suburban',
    'Location_Category_Urban'
]

def main():
    spark = SparkSession.builder.appName("BronzeToSilverCompatible").getOrCreate()

    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º "—Å—ã—Ä—ã–µ" –¥–∞–Ω–Ω—ã–µ
    df = spark.read.parquet("/opt/data/bronze")

    # 2. –û—á–∏—â–∞–µ–º
    df = df.dropna()
    df = df.filter(col("Number_of_Drivers") <= 60)

    # 3. –ü—Ä–∏–≤–æ–¥–∏–º Vehicle_Type –∫ —á–∏—Å–ª—É
    df = df.withColumn(
        "Vehicle_Type",
        when(col("Vehicle_Type") == "Economy", 0)
        .when(col("Vehicle_Type") == "Premium", 1)
        .otherwise(None)
    )

    # 4. –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ pandas
    pdf = df.toPandas()

    # 5. –û—Å—Ç–∞–≤–ª—è–µ–º –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    pdf = pdf[[
        'Number_of_Riders', 'Number_of_Drivers', 'Number_of_Past_Rides',
        'Average_Ratings', 'Vehicle_Type', 'Expected_Ride_Duration',
        'Time_of_Booking', 'Customer_Loyalty_Status', 'Location_Category', 'Historical_Cost_of_Ride'
    ]]

    # 6. One-hot –∫–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ
    pdf = pd.get_dummies(pdf, columns=[
        'Time_of_Booking', 'Customer_Loyalty_Status', 'Location_Category'
    ])

    # 7. –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    for column in expected_columns:
      if column not in pdf.columns:
          pdf[column] = 0

    # 8. –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º
    pdf = pdf[expected_columns + ['Historical_Cost_of_Ride']]

    # 9. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ Spark DataFrame –≤ Silver
    spark_df = spark.createDataFrame(pdf)
    spark_df.write.mode("overwrite").parquet("/opt/data/silver")

    spark.stop()

if __name__ == "__main__":
    main()